Разработка сверточной нейронной сети на базе фреймворка TensorFlow Python для определения вида цветка по изображению.

Авторы:
Cамохов Даниил и Белкин Никита

Группа:
15.27д-пи05/25б

Введение:
Рост разнообразия видов растений и необходимость их быстрой идентификации по изображению важны для экологии, сельского хозяйства и ботанических исследований, однако ручное определение требует высокой квалификации экспертов и занимает много времени. При большом потоке полевых фотографий и пользовательских снимков классические методы обработки изображений и простые статистические модели не способны учитывать сложные нелинейные различия в форме, текстуре и окраске цветков, что приводит к снижению точности распознавания видов.

Аналоги:
Во многих исследованиях и приложениях уже используются системы автоматического распознавания растений по изображениям, что задаёт контекст для твоей работы.
Мобильные приложения
	•	Сервисы Pl@ntNet, Plant.id, Flora Incognita и похожие приложения позволяют пользователю сделать фото растения и получить предположения о виде на основе глубинных моделей компьютерного зрения. 
	•	Их цель — массовая, удобная для пользователей идентификация растений, но точность сильно зависит от качества снимка, а используемые модели и датасеты, как правило, закрыты. 
  Научные и открытые проекты
	•	Существует большое число академических работ по классификации цветов на датасетах tf_flowers и Oxford Flowers 102 с помощью CNN, ResNet, EfficientNet и Vision Transformer; в них достигают точности 90–98 % и выше. 
	•	Открытые репозитории на GitHub реализуют похожие задачи классификации цветов с помощью TensorFlow/Keras и PyTorch, но чаще без удобного веб‑интерфейса и без акцента на настраиваемости архитектуры и гиперпараметров для учебных целей.

Графики обучения алгоритмов
<img width="1189" height="390" alt="Unknown" src="https://github.com/user-attachments/assets/aa79320b-150d-495c-9cdf-119adfa8fed6" />
На левом графике видно, что и обучающая, и валидационная точность постепенно растут от эпохи к эпохе, что говорит о том, что модель действительно учится: правильных классификаций становится больше как на обучающей, так и на проверочной выборке.
	•	На правом графике обе кривые функции потерь (обучающая и валидационная) монотонно уменьшаются, при этом валидационная ошибка снижается сопоставимо с обучающей, что говорит об отсутствии сильного переобучения на рассматриваемом интервале эпох.
  
<img width="1189" height="390" alt="Unknown-2" src="https://github.com/user-attachments/assets/e7d39555-1516-4f67-bf6b-c17dcb1ddf21" />
На этих графиках показано обучение модифицированной CNN с L2‑регуляризацией (Алгоритм 2, Adam, L2).
	•	Левый график: и обучающая, и валидационная точность растут быстрее и достигают заметно более высоких значений по сравнению с базовой моделью, причём кривая валидации идёт чуть выше обучающей, что говорит о хорошем обобщении и сдержанном переобучении за счёт L2‑штрафа.
	•	Правый график: обе функции потерь уверенно убывают, при этом валидационная ошибка снижается почти параллельно обучающей, что подтверждает устойчивость обучения и эффективность L2‑регуляризации для данной архитектуры.
  
<img width="1189" height="390" alt="Unknown-3" src="https://github.com/user-attachments/assets/11687e51-52b0-44c5-8053-5ae5f5990168" />
На этих графиках показано обучение базовой CNN с оптимизатором SGD (Алгоритм 3).
	•	Левый график: точность растёт значительно медленнее, чем у вариантов с Adam, и остаётся на низком уровне; к тому же кривая валидационной точности заметно колеблется, что указывает на менее стабильное и более медленное обучение при выбранных настройках SGD.
	•	Правый график: функция потерь и на обучении, и на валидации убывает, но снижение более пологое, а разрыв между кривыми остаётся, что говорит о том, что SGD с текущим шагом обучения хуже использует данные и требует либо более тонкой настройки гиперпараметров, либо более длинного обучения по сравнению с Adam.

  <img width="1189" height="390" alt="Unknown-4" src="https://github.com/user-attachments/assets/2fdb515f-9e38-4348-a468-76dd45d16d10" />
  На графиках показано обучение модели с предобученной MobileNetV2 с замороженными сверточными слоями (Алгоритм 4).
	•	Левый график: точность на обучении и валидации почти не растёт и остаётся на очень низком уровне, что означает, что при замороженной базе и небольшом числе эпох модель практически не дообучается под конкретный датасет.
	•	Правый график: функция потерь медленно убывает, но без заметного улучшения точности, что указывает на то, что одного лишь обучения «головы» поверх замороженной MobileNetV2 недостаточно — требуется либо разморозить часть базовых слоёв для тонкой донастройки, либо увеличить число эпох и/или изменить гиперпараметры.

  <img width="1189" height="390" alt="Unknown-5" src="https://github.com/user-attachments/assets/1e311927-125d-4df3-abdb-f1dfd18283c2" />
  На этих графиках показано обучение модели с дообучением MobileNetV2 (fine‑tuning, Алгоритм 5).
	•	Левый график: обучающая точность быстро растёт от эпохи к эпохе, что говорит о том, что размороженные слои MobileNetV2 хорошо подстраиваются под датасет; при этом валидационная точность почти не улучшается, что указывает на переобучение модели на обучающей выборке.
	•	Правый график: обучающая функция потерь уверенно убывает, тогда как валидационная функция потерь сначала растёт, а затем лишь чуть снижается, подтверждая, что при данном режиме fine‑tuning модель переобучается и требует более сильной регуляризации или уменьшения степени дообучения предобученной базы.


Архитектура модели:
Выбранный фреймворк: TensorFlow/Keras
Архитектура сети — это глубокая сверточная нейросеть

Входной слой: 180×180×3180×180×3 нейронов (пикселей), активация линейная (после этого сразу идут сверточные слои с ReLU).
Скрытый слой 1: сверточный слой Conv2D с 64 фильтрами (аналог 64 нейронов), функция активации ReLU, с L2‑регуляризацией c коэффициентом 0.001 на веса этого слоя
Скрытый слой 2: сверточный слой Conv2D с 128 фильтрами (аналог 128 нейронов), функция активации ReLU, с L2‑регуляризацией (0.001) и последующим слоем подвыборки MaxPooling2D для уменьшения размерности признаков. Выходной слой: полносвязный слой Dense с числом нейронов, равным числу классов датасета (например, 102 для Oxford Flowers 102), с функцией активации softmax для получения распределения вероятностей по видам растений

Описание гиперпараметров:
В сети используются две основные функции активации:
ReLU (Rectified Linear Unit) — во всех скрытых слоях (сверточных и полносвязных), чтобы модель эффективно учила нелинейные зависимости и быстрее сходилась при обучении.​
Softmax — в выходном слое, чтобы превратить выходные значения в вероятности по всем классам (видам растений) и выбрать наиболее вероятный.
Алгоритм оптимизации - алгоритм оптимизации Adam (Adaptive Moment Estimation) Используется функция потерь sparse categorical cross‑entropy (разреженная категориальная кросс‑энтропия
Количество эпох: 8
Размер батча: 32

DATASET:
Источник данных: датасет изображений цветов (например, oxford_flowers102 из TensorFlow Datasets)
Метод получения данных:
Загрузка датасета напрямую через API TensorFlow Datasets (tfds.load)
Автоматическая загрузка и распаковка изображений и меток классов
Поддержка 102 видов цветов (102 класса изображений)tensorflow+1​
Что вводит пользователь:
Выбор датасета/подмножества: train, validation или test
Параметры обучения: количество эпох, размер батча, скорость обучения
Параметры аугментации: включена/выключена, степень поворота, отражения и зума
Предобработка данных:
Масштабирование пикселей: перевод в диапазон [0,1][0, 1][0,1] делением на 255
Изменение размера изображений до фиксированного формата (например, 180×180×3)
Аугментация данных: случайный поворот, отражение, зум для увеличения разнообразия выборкиtensorflow+1​
Разделение по готовым сплитам датасета: обучение, валидация, тест
5.   Характеристики датасета:
Цветные изображения реальных цветов (фотографии)
Многоклассовая разметка: каждый снимок относится к одному из 102 видов
Однородный формат данных, пригодный для обучения сверточных сетей (RGB‑изображения)towardsdatascience+1​
Возможность загрузки полного набора или отдельных частей (train/val/test) для экспериментов с архитектурой и гиперпараметрами

Как можно доработать НС:
Использовать transfer learning. Взять предобученную модель (например, ResNet50 или EfficientNet из TensorFlow Hub), заменить верхний классификатор на свои слои и дообучить на датасете цветов — обычно даёт резкий рост точности.​
Углубить архитектуру. Добавить больше сверточных блоков, batch‑нормализацию и более сильную аугментацию (резкие повороты, цветовые сдвиги), чтобы сеть лучше обобщала на сложные и шумные фото.​
Добавить внимание и баланс классов. Вставить spatial/channel attention‑модули поверх фич‑карт, а в функцию потерь добавить веса классов или focal loss, чтобы улучшить распознавание редко встречающихся видов растений.​
 
